{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/objectc/CNN-with-TensorFlow2.0-and-Keras/blob/master/Resnet_residual_block.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnpkAcPxZGzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import needed classes\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,AveragePooling2D,Dropout,BatchNormalization,Activation, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from math import ceil\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwGns0UdZKhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Unit(x,filters,pool=False):\n",
        "    res = x\n",
        "    if pool:\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        res = Conv2D(filters=filters,kernel_size=[1,1],strides=(2,2),padding=\"same\")(res)\n",
        "    out = BatchNormalization()(x)\n",
        "    out = Activation(\"relu\")(out)\n",
        "    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=\"same\")(out)\n",
        "\n",
        "    out = BatchNormalization()(out)\n",
        "    out = Activation(\"relu\")(out)\n",
        "    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=\"same\")(out)\n",
        "\n",
        "    out = keras.layers.add([res,out])\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtG2k0coZN6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the model\n",
        "\n",
        "\n",
        "def MiniModel(input_shape):\n",
        "    images = Input(input_shape)\n",
        "    net = Conv2D(filters=32, kernel_size=[3, 3], strides=[1, 1], padding=\"same\")(images)\n",
        "    net = Unit(net,32)\n",
        "    net = Unit(net,32)\n",
        "    net = Unit(net,32)\n",
        "\n",
        "    net = Unit(net,64,pool=True)\n",
        "    net = Unit(net,64)\n",
        "    net = Unit(net,64)\n",
        "\n",
        "    net = Unit(net,128,pool=True)\n",
        "    net = Unit(net,128)\n",
        "    net = Unit(net,128)\n",
        "    net = Unit(net, 256,pool=True)\n",
        "    net = Unit(net, 256)\n",
        "    net = Unit(net, 256)\n",
        "\n",
        "    net = BatchNormalization()(net)\n",
        "    net = Activation(\"relu\")(net)\n",
        "    net = Dropout(0.25)(net)\n",
        "\n",
        "    net = AveragePooling2D(pool_size=(4,4))(net)\n",
        "    net = Flatten()(net)\n",
        "    net = Dense(units=10,activation=\"softmax\")(net)\n",
        "\n",
        "    model = Model(inputs=images,outputs=net)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br7gwp0HZXH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4452a12-7d8a-4c44-927a-0f33c2c4248f"
      },
      "source": [
        "#load the cifar10 dataset\n",
        "(train_x, train_y) , (test_x, test_y) = cifar10.load_data()\n",
        "\n",
        "#normalize the data\n",
        "train_x = train_x/255\n",
        "test_x = test_x/255\n",
        "#Subtract the mean image from both train and test set\n",
        "# train_x = train_x - train_x.mean()\n",
        "# test_x = test_x - test_x.mean()\n",
        "\n",
        "#Divide by the standard deviation\n",
        "# train_x = train_x / train_x.std(axis=0)\n",
        "# test_x = test_x / test_x.std(axis=0)\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=10,\n",
        "                             width_shift_range=5. / 32,\n",
        "                             height_shift_range=5. / 32,\n",
        "                             rescale=1./255,\n",
        "                             horizontal_flip=True)\n",
        "\n",
        "# Compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(train_x)\n",
        "\n",
        "\n",
        "\n",
        "#Encode the labels to vectors\n",
        "train_y = keras.utils.to_categorical(train_y,10)\n",
        "test_y = keras.utils.to_categorical(test_y,10)\n",
        "\n",
        "#define a common unit\n",
        "\n",
        "\n",
        "input_shape = (32,32,3)\n",
        "model = MiniModel(input_shape)\n",
        "\n",
        "#Print a Summary of the model\n",
        "\n",
        "model.summary()\n",
        "#Specify the training components\n",
        "model.compile(optimizer=Adam(0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 32, 32, 32)   896         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 32)   128         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 32)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 32, 32, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 32, 32, 32)   128         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 32, 32, 32)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 32, 32, 32)   9248        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 32, 32, 32)   0           conv2d_56[0][0]                  \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 32)   128         add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 32)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 32, 32, 32)   9248        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 32, 32, 32)   128         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 32, 32, 32)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 32, 32, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 32, 32, 32)   0           add_24[0][0]                     \n",
            "                                                                 conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 32, 32, 32)   128         add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 32)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 32, 32, 32)   9248        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 32, 32, 32)   128         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 32, 32, 32)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 32, 32, 32)   9248        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 32, 32, 32)   0           add_25[0][0]                     \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 32)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 32)   128         max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 32)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 64)   18496       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 64)   256         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 64)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 64)   2112        add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 64)   36928       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 16, 16, 64)   0           conv2d_63[0][0]                  \n",
            "                                                                 conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 64)   256         add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 64)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 64)   36928       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 64)   256         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 64)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 16, 16, 64)   0           add_27[0][0]                     \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 64)   256         add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 64)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 16, 16, 64)   36928       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 64)   256         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 64)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 16, 16, 64)   36928       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 16, 16, 64)   0           add_28[0][0]                     \n",
            "                                                                 conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 8, 8, 64)     256         max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 8, 8, 64)     0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 128)    73856       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 8, 8, 128)    512         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 8, 8, 128)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 128)    8320        add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 128)    147584      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 8, 8, 128)    0           conv2d_70[0][0]                  \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 8, 8, 128)    512         add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 128)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 128)    147584      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 8, 8, 128)    512         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 8, 8, 128)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 128)    147584      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 8, 8, 128)    0           add_30[0][0]                     \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 128)    512         add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 128)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 128)    147584      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 128)    512         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 128)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 128)    147584      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 8, 8, 128)    0           add_31[0][0]                     \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 128)    0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 4, 4, 128)    512         max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 4, 4, 128)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 4, 4, 256)    295168      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 4, 4, 256)    1024        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 4, 4, 256)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 4, 4, 256)    33024       add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 4, 4, 256)    590080      activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 4, 4, 256)    0           conv2d_77[0][0]                  \n",
            "                                                                 conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 4, 4, 256)    1024        add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 4, 4, 256)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 4, 4, 256)    590080      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 4, 4, 256)    1024        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 4, 4, 256)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 4, 4, 256)    590080      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 4, 4, 256)    0           add_33[0][0]                     \n",
            "                                                                 conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 4, 4, 256)    1024        add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 4, 4, 256)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 4, 4, 256)    590080      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 4, 4, 256)    1024        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 256)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 4, 4, 256)    590080      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 4, 4, 256)    0           add_34[0][0]                     \n",
            "                                                                 conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 256)    1024        add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 256)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 4, 4, 256)    0           activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 256)    0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 256)          0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           2570        flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,374,538\n",
            "Trainable params: 4,368,714\n",
            "Non-trainable params: 5,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErjiTblBc7mz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d431f211-4873-44da-b067-884f72901bd6"
      },
      "source": [
        "epochs = 50\n",
        "steps_per_epoch = ceil(50000/128)\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit(datagen.flow(train_x, train_y, batch_size=128),\n",
        "                    validation_data=(test_x,test_y),\n",
        "                    epochs=epochs,\n",
        "                    steps_per_epoch=steps_per_epoch, \n",
        "                    verbose=1\n",
        "                   )\n",
        "\n",
        "\n",
        "#Evaluate the accuracy of the test dataset\n",
        "accuracy = model.evaluate(x=test_x,y=test_y,batch_size=128)\n",
        "model.save(\"cifar10model.h5\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 47s 119ms/step - loss: 0.7974 - accuracy: 0.7197 - val_loss: 1.0746 - val_accuracy: 0.6370\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.6756 - accuracy: 0.7651 - val_loss: 0.7172 - val_accuracy: 0.7643\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.5920 - accuracy: 0.7939 - val_loss: 0.8542 - val_accuracy: 0.7266\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.5348 - accuracy: 0.8128 - val_loss: 0.7105 - val_accuracy: 0.7519\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.4935 - accuracy: 0.8263 - val_loss: 0.6186 - val_accuracy: 0.7840\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.4588 - accuracy: 0.8391 - val_loss: 0.6526 - val_accuracy: 0.7835\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.4263 - accuracy: 0.8505 - val_loss: 0.7532 - val_accuracy: 0.7562\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.4001 - accuracy: 0.8617 - val_loss: 0.5909 - val_accuracy: 0.8005\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.3714 - accuracy: 0.8715 - val_loss: 0.6693 - val_accuracy: 0.7848\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.3582 - accuracy: 0.8756 - val_loss: 0.7931 - val_accuracy: 0.7609\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.3380 - accuracy: 0.8820 - val_loss: 0.5645 - val_accuracy: 0.8177\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.3248 - accuracy: 0.8866 - val_loss: 0.5814 - val_accuracy: 0.8076\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.3085 - accuracy: 0.8917 - val_loss: 0.8195 - val_accuracy: 0.7610\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.2930 - accuracy: 0.8973 - val_loss: 0.6537 - val_accuracy: 0.7986\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.2796 - accuracy: 0.9033 - val_loss: 0.5078 - val_accuracy: 0.8348\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.2633 - accuracy: 0.9088 - val_loss: 0.5636 - val_accuracy: 0.8191\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.2583 - accuracy: 0.9091 - val_loss: 0.4867 - val_accuracy: 0.8427\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.2447 - accuracy: 0.9142 - val_loss: 0.4811 - val_accuracy: 0.8470\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.2417 - accuracy: 0.9154 - val_loss: 0.4979 - val_accuracy: 0.8396\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.2265 - accuracy: 0.9214 - val_loss: 0.6479 - val_accuracy: 0.8146\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.2207 - accuracy: 0.9217 - val_loss: 0.5604 - val_accuracy: 0.8271\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.2089 - accuracy: 0.9263 - val_loss: 0.6279 - val_accuracy: 0.8280\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.2041 - accuracy: 0.9286 - val_loss: 0.4929 - val_accuracy: 0.8458\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1956 - accuracy: 0.9304 - val_loss: 0.4761 - val_accuracy: 0.8559\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.1921 - accuracy: 0.9323 - val_loss: 0.5167 - val_accuracy: 0.8432\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.1863 - accuracy: 0.9346 - val_loss: 0.3911 - val_accuracy: 0.8805\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.1746 - accuracy: 0.9392 - val_loss: 0.5724 - val_accuracy: 0.8450\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1728 - accuracy: 0.9386 - val_loss: 0.4788 - val_accuracy: 0.8522\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1587 - accuracy: 0.9429 - val_loss: 0.4386 - val_accuracy: 0.8711\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.1626 - accuracy: 0.9411 - val_loss: 0.5587 - val_accuracy: 0.8473\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.1545 - accuracy: 0.9451 - val_loss: 0.5820 - val_accuracy: 0.8355\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.1496 - accuracy: 0.9468 - val_loss: 0.4293 - val_accuracy: 0.8769\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1445 - accuracy: 0.9489 - val_loss: 0.4601 - val_accuracy: 0.8688\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.1413 - accuracy: 0.9497 - val_loss: 0.6557 - val_accuracy: 0.8369\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1378 - accuracy: 0.9502 - val_loss: 0.5535 - val_accuracy: 0.8485\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1350 - accuracy: 0.9523 - val_loss: 0.4828 - val_accuracy: 0.8637\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1296 - accuracy: 0.9528 - val_loss: 0.5931 - val_accuracy: 0.8450\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 46s 118ms/step - loss: 0.1272 - accuracy: 0.9551 - val_loss: 0.5091 - val_accuracy: 0.8631\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1223 - accuracy: 0.9565 - val_loss: 0.5216 - val_accuracy: 0.8653\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1179 - accuracy: 0.9585 - val_loss: 0.4584 - val_accuracy: 0.8750\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1184 - accuracy: 0.9578 - val_loss: 0.5003 - val_accuracy: 0.8652\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 0.1159 - accuracy: 0.9590 - val_loss: 0.7621 - val_accuracy: 0.8098\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1108 - accuracy: 0.9606 - val_loss: 0.4774 - val_accuracy: 0.8764\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1082 - accuracy: 0.9616 - val_loss: 0.4157 - val_accuracy: 0.8845\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1064 - accuracy: 0.9615 - val_loss: 0.3507 - val_accuracy: 0.8963\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1055 - accuracy: 0.9630 - val_loss: 0.5334 - val_accuracy: 0.8593\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.1032 - accuracy: 0.9630 - val_loss: 0.4263 - val_accuracy: 0.8816\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.0988 - accuracy: 0.9648 - val_loss: 0.5046 - val_accuracy: 0.8758\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.0989 - accuracy: 0.9654 - val_loss: 0.4969 - val_accuracy: 0.8657\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 0.0965 - accuracy: 0.9648 - val_loss: 0.4041 - val_accuracy: 0.8853\n",
            "10000/10000 [==============================] - 2s 171us/sample - loss: 0.4063 - accuracy: 0.8853\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}